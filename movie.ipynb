{"cells":[{"cell_type":"code","source":["# Set up AWS S3 access credentials\nACCESS_KEY = \"KEY_HERE\"\nSECRET_KEY = \"KEY_HERE\"\nENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\nAWS_BUCKET_NAME = \"comp4651-movie-data\""],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# Convert csv file to spark data frame\n# INPUT: \n# fileName: the full file name(e.g. \"file.csv\"), \n# fileSchema: the schema (StructType Array with StructField)\n# OUTPUT:\n# Spark DataFrame\ndef loadDataFrame(fileName, fileSchema):\n  return (spark.read.format(\"csv\")\n                    .schema(fileSchema)\n                    .option(\"header\", \"true\")\n                    .option(\"mode\", \"DROPMALFORMED\")\n                    .csv(\"s3a://%s:%s@%s/%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME, fileName)))"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["from pyspark.sql.types import *\n\nmovieRatingSchema = StructType([\n    StructField(\"userId\", IntegerType(), True),\n    StructField(\"movieId\", IntegerType(), True),\n    StructField(\"rating\", FloatType(), True),\n    StructField(\"timestamp\", StringType(), True)])\n\nmovieSchema = StructType([\n    StructField(\"movieId\", IntegerType(), True),\n    StructField(\"title\", StringType(), True),\n    StructField(\"genres\", StringType(), True)])\n\nsmallMovieRatingsDF = loadDataFrame(\"ratings-small.csv\", movieRatingSchema).cache()\nsmallMoviesDF = loadDataFrame(\"movies-small.csv\", movieSchema).cache()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# Print out the DataFrame shcema, and a few lines as example\nsmallMovieRatingsDF.printSchema()\nprint smallMovieRatingsDF.take(3)\n\nsmallMoviesDF.printSchema()\nprint smallMoviesDF.take(3)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["(trainingSet, testingSet) = smallMovieRatingsDF.randomSplit([0.8, 0.2], seed=12345L)\ntestingForPrediction = testingSet.rdd.map(lambda x: (x.userId, x.rating))\n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# Use ml instead of mlib for Dataframes\n# http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.recommendation.ALS\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.sql import Row\n\n# Build the recommendation model using ALS on the training data\n# Note: set cold start strategy to 'drop' to ensure not to have NaN evaluation metrics\nals = ALS(maxIter=10, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\nmodel = als.fit(trainingSet)\n\n# Evaluate the model by computing the RMSE on the test data\npredictions = model.transform(testingSet)\npredictions = predictions.dropna()\nprint predictions.take(4)\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\nrmse = evaluator.evaluate(predictions)\nprint rmse\nprint(\"Root-mean-square error = \" + str(rmse))\n"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#To be deleted below\n# Collaborative Filtering - RDD-based API\n# https://spark.apache.org/docs/2.1.0/mllib-collaborative-filtering.html\nfrom pyspark.mllib.recommendation import ALS\nimport math\n\nseed = 12345L\niterations = 10\nregularization_parameter = 0.1\nranks = [4, 8, 12]\nerrors = [0, 0, 0]\nerr = 0\ntolerance = 0.02\n\nmin_error = float('inf')\nbest_rank = -1\nbest_iteration = -1\nfor rank in ranks:\n    model = ALS.train(trainingSetRDD, rank, seed=seed, iterations=iterations,\n                      lambda_=regularization_parameter)\n    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n    rates_and_preds = validationSetRDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n    errors[err] = error\n    err += 1\n    print 'For rank %s the RMSE is %s' % (rank, error)\n    if error < min_error:\n        min_error = error\n        best_rank = rank\n\nprint 'The best model was trained with rank %s' % best_rank"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["print predictions.take(3)\nprint rates_and_preds.take(3)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["model = ALS.train(trainingSetRDD, best_rank, seed=seed, iterations=iterations,\n                      lambda_=regularization_parameter)\npredictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\nrates_and_preds = testingSetRDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\nerror = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n    \nprint 'For testing data the RMSE is %s' % (error)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["my_movie = sc.parallelize([(2, 1029)])\nindividual_movie_rating_RDD = model.predictAll(my_movie)\nprint individual_movie_rating_RDD.collect()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":11}],"metadata":{"name":"movie-test","notebookId":3619855571353653},"nbformat":4,"nbformat_minor":0}
